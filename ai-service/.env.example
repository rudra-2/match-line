# AI Service Environment Variables

# Server Configuration
PORT=8000
HOST=0.0.0.0
DEBUG=True

# ============================================
# LLM Provider Selection
# ============================================
# Options: "openai", "ollama", "custom"
# - openai: Best quality, requires API key ($$$)
# - ollama: FREE local LLM (recommended for development)
# - custom: Any OpenAI-compatible API

LLM_PROVIDER=ollama

# ============================================
# OpenAI Configuration (if LLM_PROVIDER=openai)
# ============================================
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo
# OPENAI_BASE_URL=  # Optional: for custom OpenAI-compatible endpoint

# ============================================
# Ollama Configuration (if LLM_PROVIDER=ollama)
# ============================================
# FREE LOCAL LLM - Install from https://ollama.ai
# Popular models: llama3.1, mistral, codellama, phi3
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# To install Ollama:
# 1. Download from https://ollama.ai
# 2. Run: ollama pull llama3.1
# 3. Service starts automatically

# ============================================
# Custom API Configuration (if LLM_PROVIDER=custom)
# ============================================
# CUSTOM_API_URL=https://api.groq.com/openai/v1
# CUSTOM_API_KEY=your-api-key

# ============================================
# Embeddings Provider Selection
# ============================================
# Options: "openai", "ollama", "local"
# - openai: Best quality, requires API key
# - ollama: FREE local embeddings (nomic-embed-text)
# - local: FREE offline (sentence-transformers)

EMBEDDING_PROVIDER=ollama

# OpenAI Embeddings (if EMBEDDING_PROVIDER=openai)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama Embeddings (if EMBEDDING_PROVIDER=ollama)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# Run: ollama pull nomic-embed-text

# Local Embeddings (if EMBEDDING_PROVIDER=local)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================
# General LLM Parameters
# ============================================
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
LLM_TIMEOUT=30
